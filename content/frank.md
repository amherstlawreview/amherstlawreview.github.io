---
title: Adam Frank
---

{{< rawhtml >}}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Article Title - Yale Law Journal Style</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <div class="article-header">
      <h1 class="article-title">The AI-Authorship Copyright Question: How a Court Case and a Bureaucratic Decision Changed Intellectual Property Law</h1>
      <p class="author">Adam Frank – Columbia University</p>
    </div>
  </header>
  <main>
    <section class="content">
      <article>
        <p>The Supreme Court based its ruling against granting copyright privileges to AI-authored works on a narrow construction of the word "individual," in <em>Thaler v. Vidal</em>. This article explores the consequences of this decision in terms of the (1) moral imperatives that might guide interaction with AI, (2) separation of powers between judicial and executive branches of government, and (3) the relationship between human and machine producers in a competitive market. The final analysis reveals that <em>Thaler</em> is likely to carry increasing legal authority moving forward, despite the fact that it is not necessarily beneficial to keep AI out of the market.</p>

        <h3>Introduction</h3>

        <p>The emergence of advanced artificial intelligence, capable of producing creative and original works, created an intellectual property problem: could these works be granted privileges in American copyright law? There was no law that stated they could not, but the laws that govern intellectual property were not written with AI in mind. According to the Chevron doctrine—which says that "courts should defer to an agency's reasonable interpretation of an ambiguous statute"<sup><a href="#fn82" class="footnote-link">82</a></sup> – entities like the U.S. Copyright Office have significant discretionary power in deciding whether or not existing law allows AI-authored works to get IP protections. In 2024, the Supreme Court is expected, by many, to discard the Chevron doctrine,<sup><a href="#fn83" class="footnote-link">83</a></sup> creating a legal environment in which judges will determine what to do with AI-produced works and IP, with less guidance from the executive branch. This change creates an expectation that the 2022 decision in <em>Thaler v Vidal</em>, which assigned a narrow construction to the word "individual," will become a more important source of legal authority, moving forward.</p>

        <p><em>Thaler</em> established that AI programs cannot hold copyrights, on the grounds that an AI program is not an "individual." With the court's holding poised to become more authoritative in banning AI-authored works from the market, two important issues emerge: (1) the narrow construction of the word "individual" in <em>Thaler</em> is somewhat arbitrary, and (2) it is not necessarily beneficial to keep AI-authored works out of the marketplace.</p>

        <p>Stephen Thaler applied for a patent on behalf of an AI program, acknowledging that the "invention [was] generated by artificial intelligence."<sup><a href="#fn84" class="footnote-link">84</a></sup> His application was denied before failing on appeal. The appellate court ruled that only an object of human production is protected under the Patent Act.<sup><a href="#fn85" class="footnote-link">85</a></sup> This holding did not totally resolve the question because it did not determine where the line between human-augmented and totally-automated are delineated. If AI programs alone cannot receive legal privileges for their creations, how would the law apply to cases of joint authorship between humans and AI?</p>

        <p>In 2022, Kristina Kashtanova published a graphic novel with AI-generated illustrations. After initially granting a copyright for the work, the USCO canceled her registration. A month after canceling the registration, the USCO announced that it would – all of a sudden – allow AI-authorship.<sup><a href="#fn86" class="footnote-link">86</a></sup> Not only did the development contradict the cancellation of Kashtanova's earlier copyright, it also seemed close to contradicting <em>Thaler</em>. Although, it is important to note that a human-AI co-authored work does have a human author, and is thus within <em>Thaler</em>'s narrow construction of "individual." While the USCO's initial decision about the Kashtanova copyright appeared to exclude AI authors, its subsequent rule change suggested the prospect of more inclusive policies. The USCO presented contradictory leanings with regard to the underlying legal ambiguity, despite <em>Thaler</em> and despite the logic that the Chevron doctrine depends on. Why then, one might ask, is this such a difficult question for legal authorities?</p>

        <h3>Background: The Utilitarian Gray Area</h3>

        <p>Despite <em>Thaler</em>, the law is ambiguous over the question of granting copyrights and other intellectual property privileges to AI. There are two flavors of approaches to the issue, one is judicial and the other is political. The judicial answer is that some laws have narrow wording, such as "individual," that could be argued to preclude AI. The <em>Thaler</em> decision depends on this reasoning.<sup><a href="#fn87" class="footnote-link">87</a></sup> If <em>Thaler</em> categorically bans granting IP protections to AI-authored works, that is a judicial solution to this question. The political approach is acknowledging that there is a danger to human competitors in the market if non-human alternatives are able to produce comparable work and receive the same legal privileges. Of the two classes of approaches, the judicial approach is the useful one, if for no other reason than the recalcitrant nature of the political process.</p>

        <p>The issue with <em>Thaler</em> is that the narrow construction of "individual" is somewhat arbitrary. Both narrow and broad constructions for words like "individual" and "person" have been applied to different laws, and there is not a clear a priori reason that a narrow or broad construction is better than the other. For example, the construction of "person" used in the Equal Rights Amendment includes companies.<sup><a href="#fn88" class="footnote-link">88</a></sup> But the Torture Victims Protection Act only understands "individual" as a human being.<sup><a href="#fn89" class="footnote-link">89</a></sup> One could say that "individual" and "person" are sufficiently disanalogous for this to be a non-issue, but they are essentially synonyms and laws are generally understood to be based on the meaning of words within the language at the time of writing. Arguing that there exists some special reason that the word "person" has a broader meaning than "individual" is somewhat suspect.</p>

        <p>Like the judicial solution, the political solution also depends on relatively uncertain logic. If AI-authorship could be proven to be bad for human artists, congress could simply ban such works. One could say that the political solution might rely on the assumption that congress needs to change the law because existing law is incoherent. Legal scholar Margot Kaminski points out that a foundational "purpose of copyright law…[is] to incentivize (presumably human) authors to create new works for the benefit of net social welfare."<sup><a href="#fn90" class="footnote-link">90</a></sup> If allowing AI into the creative market disincentivizes all human competitors, a situation emerges where a law that exists to incentivize actually disincentivizes. Self-contradictory laws can be said to need amendment so as to not self-contradict. The problem with a political solution, however, is that it depends on the assumption that congress legislates according to efficiency and collective benefit, rather than politics.</p>

        <p>Both <em>Thaler</em> and Kashtanova failed to gain IP protections, which suggests that authorities lean toward excluding AI-authored works. Without a mandate from congress forcing them to ban these works, and with the Chevron doctrine's uncertain future, the <em>Thaler</em> decision has become an important source of legal authority. Before discussing the reasoning behind this important decision, however, it is important to consider the relationship between humans and AI in the competitive market.</p>

        <h3>Fear the Machines: A Psychological Framework</h3>

        <p>There is a deep-seated human paranoia about AI programs undermining economic opportunity. People assume that technology will make human labor obsolete, and workers will cease to earn a living. Fear, it might be said, lies at the heart of academics Julia Kirby and Thomas Davenport's "automation vs. augmentation" model of AI. They argue that "… the reason people hate automation is that it involves someone in a managerial position spotting a shortcoming or limitation in employees, or simply a weakness relative to machine performance, and then punishing them for that weakness."<sup><a href="#fn91" class="footnote-link">91</a></sup></p>

        <p>Indeed, the human "weakness" relative to AI appears to have been assumed without further consideration. The "assumption of diminished utility" happens when authorities assume that granting privileges for AI-authored works will competitively hurt human producers, despite evidence to the contrary. Perhaps, for example, the market value of the average originally composed pop song would decrease if AI programs could compose high-quality ones rapidly and gain copyright privileges, allowing AI-authored works to flood the market.</p>

        <p>The first issue with this logic, is that it is not clear that the best AI-produced song, for example, is competitive in the current market when compared to the average composition written by a professional-level human songwriter. Indeed, if it is not competitive, the value of high-quality human creations would continue to hold and offer the prospect of profitability due to a quality premium. Wage-earning human artists would be insulated. Only low-quality works would flood the market. Quality discrepancy, then, is the first consideration that suggests it is inappropriate to assume that awarding AI such IP privileges will disincentivize human artists.</p>

        <p>The next flaw with the diminished utility assumption might be called "the rate of production principle": human artists that co-author with AI increase their output by more than the value they lose by letting AI into the market. They stand to make more money co-authoring with AI than by producing works without AI. For example, if an author working alone can only write one book a year, he makes more money splitting the copyright privileges with an AI and producing ten books per year, despite the market value of the average book being lower. It follows that utilitarian considerations may still support granting privileges for AI-authored works. The rate of production principle suggests that granting AI-authored works copyright privileges will result in the artists making more money than in the pre-AI era because, despite sacrificing a portion of the copyright to the AI, their productive output increases by many multiples. Thus, utilitarian considerations do not unambiguously support the prohibition of such rights. Indeed, they may support the granting of such rights.</p>

        <p>Political realities see things differently. Creative-industry pressure groups have lobbied aggressively against the use of AI. Screenwriters in Hollywood brought this issue to bear in 2023.<sup><a href="#fn92" class="footnote-link">92</a></sup> Regardless of the possibility that screenwriting could become a more profitable profession under conditions of AI-human co-authorship, the fear of human obsolescence is a more salient consideration. Anxiety could be a relevant factor to this behavior; if artists stand to make more money using AI than prohibiting it, it would be rational for the guilds to support the integration of AI rather than oppose it. However, if there is widespread paranoia about the 'obsolete human artist,' then it follows that the guilds should vehemently oppose the integration of AI into creative practices. The critical issue with the integration of AI into labor could be irrational fear on behalf of humans. Importantly, generative AI cannot improve without human feedback.</p>

        <h3>AI and Legal Personhood</h3>

        <p>The question of whether AI systems should be granted legal personhood is central to the debate over AI authorship and intellectual property rights. Legal personhood would grant AI systems certain rights and responsibilities under the law, potentially including the ability to hold copyrights and other intellectual property rights.</p>

        <p>However, the concept of legal personhood for AI raises fundamental questions about the nature of personhood and the purpose of legal rights. Traditional legal personhood has been granted to human beings and, in some cases, to corporations and other entities that serve human interests. The question is whether AI systems, which are created by humans and serve human purposes, should be granted similar legal status.</p>

        <p>The <em>Thaler</em> decision provides one answer to this question by narrowly construing the term "individual" to exclude AI systems. This decision suggests that AI systems should not be granted legal personhood, at least for the purposes of intellectual property law. However, this decision is not necessarily the final word on the question, and future legal developments may provide different answers.</p>

        <h3>The Legal Basis for Exclusion in Two Cases</h3>

        <p>The legal basis for excluding AI-authored works from copyright protection can be understood by examining two key cases: <em>Thaler v. Vidal</em> and the Kashtanova case. These cases demonstrate different approaches to the question of AI authorship and provide important precedents for future legal developments.</p>

        <p>In <em>Thaler</em>, the court based its decision on a narrow construction of the term "individual" in the Patent Act. The court held that only human beings can be considered "individuals" for the purposes of patent law, and therefore AI systems cannot be granted patent rights. This decision provides a clear legal basis for excluding AI systems from certain types of intellectual property protection.</p>

        <p>The Kashtanova case, however, presents a more complex situation. Initially, the Copyright Office granted copyright protection to a work that included AI-generated illustrations. However, the office later canceled this registration, suggesting that AI-generated content cannot be protected by copyright. This decision was then followed by a policy change that appeared to allow some forms of AI authorship, creating confusion about the legal status of AI-generated works.</p>

        <p>These cases demonstrate the uncertainty and inconsistency in the current legal treatment of AI-authored works. The <em>Thaler</em> decision provides a clear precedent for exclusion, while the Kashtanova case shows how administrative agencies may take different approaches to the question. This inconsistency creates challenges for creators, businesses, and legal practitioners who need clear guidance on the legal status of AI-generated content.</p>

      </article>
      
      <!-- Footnotes -->
      <aside class="footnotes">
        <div id="fn82" class="footnote-summary">
          <span class="footnote-number">82</span> Amy Howe, "Supreme Court likely to discard Chevron" Scotusblog, (2024): https://www.scotusblog.com/2024/01/supreme-court-likely-to-discard-chevron/
        </div>
        <div id="fn83" class="footnote-summary">
          <span class="footnote-number">83</span> Ibid.
        </div>
        <div id="fn84" class="footnote-summary">
          <span class="footnote-number">84</span> Leonard Stark, Decision in Thaler v Vidal, United States Court of Appeals for the Federal Circuit, August 5, 2022, https://cafc.uscourts.gov/opinions-orders/21-2347.OPINION.8-5-2022_1988142.pdf pp.
        </div>
        <div id="fn85" class="footnote-summary">
          <span class="footnote-number">85</span> Ibid.
        </div>
        <div id="fn86" class="footnote-summary">
          <span class="footnote-number">86</span> "Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence" United States Copyright Office, March 16, 2023. https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence#footnote-7-p16191
        </div>
        <div id="fn87" class="footnote-summary">
          <span class="footnote-number">87</span> Stark, 6.
        </div>
        <div id="fn88" class="footnote-summary">
          <span class="footnote-number">88</span> Ciara, Torres-Spelliscy, "Does We the People Include Corporations" Human Rights Magazine (ABA), Volume 43 No. 2., 2017. www.americanbar.org./Torres-Spelliscy/DoesWeThePeopleIncludeCoporations
        </div>
        <div id="fn89" class="footnote-summary">
          <span class="footnote-number">89</span> "Mohamad v. Palestinian Authority." Oyez, www.oyez.org/cases/2011/11-88. Accessed 29 Apr. 2023.
        </div>
        <div id="fn90" class="footnote-summary">
          <span class="footnote-number">90</span> Margot E Kaminski, "Authorship, disrupted: AI authors in copyright and first amendment law," UC Davis Law Review 51 (2017): 597.
        </div>
        <div id="fn91" class="footnote-summary">
          <span class="footnote-number">91</span> Thomas, Davenport, and Julia Kirby, Only humans need apply: Winners and losers in the age of smart machines, New York: Harper, 2016. Pp. 61.
        </div>
        <div id="fn92" class="footnote-summary">
          <span class="footnote-number">92</span> Noam Scheiber and John Koblin, "Will a Chatbot Write the Next 'Succession'?" The New York Times, April 29, 2023. https://www.nytimes.com/2023/04/29/business/media/writers-guild-hollywood-ai-chatgpt.html
        </div>
      </aside>
    </section>
  </main>
  
  <!-- Modal for Footnote Details -->
  <div id="footnote-modal" class="modal" aria-hidden="true" role="dialog" aria-label="Footnote">
    <div class="modal-content">
      <button class="close" aria-label="Close">&times;</button>
      <div id="full-footnote-text"></div>
    </div>
  </div>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var modal = document.getElementById('footnote-modal');
      var textTarget = document.getElementById('full-footnote-text');
      var closeBtn = modal ? modal.querySelector('.close') : null;

      function openFootnote(id) {
        var fn = document.getElementById(id);
        if (fn && modal && textTarget) {
          textTarget.innerHTML = fn.innerHTML;
          modal.style.display = 'block';
          modal.setAttribute('aria-hidden', 'false');
        }
      }

      document.querySelectorAll('.footnote-link').forEach(function (a) {
        a.addEventListener('click', function (e) {
          e.preventDefault();
          var href = a.getAttribute('href') || '';
          var id = href.replace('#', '');
          openFootnote(id);
        });
      });

      function closeModal() {
        if (modal) {
          modal.style.display = 'none';
          modal.setAttribute('aria-hidden', 'true');
          if (textTarget) textTarget.innerHTML = '';
        }
      }

      if (closeBtn) {
        closeBtn.addEventListener('click', closeModal);
      }

      if (modal) {
        modal.addEventListener('click', function (e) {
          if (e.target === modal) closeModal();
        });
      }

      document.addEventListener('keydown', function (e) {
        if (e.key === 'Escape') closeModal();
      });
    });
  </script>

</body>
</html>
{{< /rawhtml >}}

<style>
body {
  font-family: "Georgia", serif;
  margin: 0;
  padding: 0;
  background-color: #f8f8f8;
  color: #333;
  line-height: 1.5;
}

.article-header {
  padding: 0 1rem;
  max-width: 60rem;
  margin: 0 auto;
}

.article-title {
  font-size: 1.6rem;
  margin: 0;
}

.author {
  font-size: 0.8rem;
  color: #FFFFFF;
}

main {
  display: block;
  padding: 2rem 1rem;
}

.content {
  display: block;
  width: 60rem;
  max-width: 100%;
  margin: 0 auto;
}

article {
  padding-right: 0;
}

aside.footnotes {
  margin-top: 3rem;
  padding-top: 1rem;
  border-top: 1px solid #e0e0e0;
}

.footnote-link {
  color: #666;
  font-size: 0.75rem;
  text-decoration: none;
  cursor: pointer;
  vertical-align: super;
  line-height: 0;
}

.footnote-link:hover {
  color: #333;
}

.footnote-summary {
  font-size: 0.9rem;
  margin-bottom: 0.75rem;
  color: #555;
  line-height: 1.4;
}

.footnote-number {
  font-size: 0.75rem;
  font-weight: bold;
  color: #666;
  margin-right: 0.4rem;
}

.modal {
  display: none;
  position: fixed;
  z-index: 1000;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background-color: rgba(0, 0, 0, 0.6);
}

.modal-content {
  background-color: #fff;
  margin: 10% auto;
  padding: 1.25rem 1.5rem;
  border-radius: 6px;
  width: 60rem;
  max-width: calc(100% - 2rem);
  box-shadow: 0 10px 30px rgba(0,0,0,0.25);
}

.close {
  background: none;
  border: none;
  color: #666;
  font-size: 1.5rem;
  cursor: pointer;
  float: right;
}

.close:hover {
  color: #000;
}
</style>


