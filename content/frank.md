---
title: Adam Frank
---

{{< rawhtml >}}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Issue 8 Article</title>
</head>
<body>
  <header>
    <div class="article-header">
      <h1 class="article-title">The AI-Authorship Copyright Question: How a Court Case and a Bureaucratic Decision Changed Intellectual Property Law</h1>
      <p class="author">Adam Frank – Columbia University</p>
    </div>
  </header>
  <main>
    <section class="content">
      <article>
The AI-Authorship Copyright Question: How a Court Case and a
Bureaucratic Decision Changed Intellectual Property Law

Adam Frank
Columbia University – Class of 2024

Abstract
The Supreme Court based its ruling against granting copyright privileges to AI-authored works
on a narrow construction of the word “individual,” in Thaler v. Vidal. This article explores the
consequences of this decision in terms of the (1) moral imperatives that might guide interaction
with AI, (2) separation of powers between judicial and executive branches of government, and
(3) the relationship between human and machine producers in a competitive market. The final
analysis reveals that Thaler is likely to carry increasing legal authority moving forward, despite
the fact that it is not necessarily beneficial to keep AI out of the market.




Introduction

        The emergence of advanced artificial intelligence, capable of producing creative and

original works, created an intellectual property problem: could these works be granted privileges

in American copyright law? There was no law that stated they could not, but the laws that govern

intellectual property were not written with AI in mind. According to the Chevron

doctrine—which says that “courts should defer to an agency’s reasonable interpretation of an

ambiguous statute”<sup><a href="#fn82" class="footnote-link">82</a></sup> – entities like the U.S. Copyright Office have significant discretionary

power in deciding whether or not existing law allows AI-authored works to get IP protections. In

2024, the Supreme Court is expected, by many, to discard the Chevron doctrine,<sup><a href="#fn83" class="footnote-link">83</a></sup> creating a legal

environment in which judges will determine what to do with AI-produced works and IP, with less

guidance from the executive branch. This change creates an expectation that the 2022 decision in


<sup><a href="#fn82" class="footnote-link">82</a></sup>
   Amy Howe, “Supreme Court likely to discard Chevron” Scotusblog, (2024):
https://www.scotusblog.com/2024/<sup><a href="#fn01" class="footnote-link">01</a></sup>/supreme-court-likely-to-discard-chevron/
<sup><a href="#fn83" class="footnote-link">83</a></sup>
   Ibid.

                                                     <sup><a href="#fn43" class="footnote-link">43</a></sup>

Thaler v Vidal, which assigned a narrow construction to the word “individual,” will become a

more important source of legal authority, moving forward. Thaler established that AI programs

cannot hold copyrights, on the grounds that an AI program is not an “individual.” With the

court’s holding poised to become more authoritative in banning AI-authored works from the

market, two important issues emerge: (1) the narrow construction of the word “individual” in

Thaler is somewhat arbitrary, and (2) it is not necessarily beneficial to keep AI-authored works

out of the marketplace.

         Stephen Thaler applied for a patent on behalf of an AI program, acknowledging that the

“invention [was] generated by artificial intelligence.”<sup><a href="#fn84" class="footnote-link">84</a></sup> His application was denied before failing

on appeal. The appellate court ruled that only an object of human production is protected under

the Patent Act.<sup><a href="#fn85" class="footnote-link">85</a></sup> This holding did not totally resolve the question because it did not determine

where the line between human-augmented and totally-automated are delineated. If AI programs

alone cannot receive legal privileges for their creations, how would the law apply to cases of

joint authorship between humans and AI?

         In 2022, Kristina Kashtanova published a graphic novel with AI-generated illustrations.

After initially granting a copyright for the work, the USCO canceled her registration. A month

after canceling the registration, the USCO announced that it would – all of a sudden – allow

AI-authorship.<sup><a href="#fn86" class="footnote-link">86</a></sup> Not only did the development contradict the cancellation of Kashtanova’s earlier

copyright, it also seemed close to contradicting Thaler. Although, it is important to note that a

human-AI co-authored work does have a human author, and is thus within Thaler’s narrow

<sup><a href="#fn84" class="footnote-link">84</a></sup>
   Leonard Stark, Decision in Thaler v Vidal, United States Court of Appeals for the Federal Circuit, August 5, 2022,
https://cafc.uscourts.gov/opinions-orders/<sup><a href="#fn21" class="footnote-link">21</a></sup>-2347.OPINION.8-5-2022_1988142.pdf pp.
<sup><a href="#fn85" class="footnote-link">85</a></sup>
   Ibid.
<sup><a href="#fn86" class="footnote-link">86</a></sup>
   “Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence” United States
Copyright Office, March <sup><a href="#fn16" class="footnote-link">16</a></sup>, 2023.
https://www.federalregister.gov/documents/2023/<sup><a href="#fn03" class="footnote-link">03</a></sup>/<sup><a href="#fn16" class="footnote-link">16</a></sup>/2023-05321/copyright-registration-guidance-works-conta
ining-material-generated-by-artificial-intelligence#footnote-7-p16191



                                                         <sup><a href="#fn44" class="footnote-link">44</a></sup>

construction of “individual.” While the USCO’s initial decision about the Kashtanova copyright

appeared to exclude AI authors, its subsequent rule change suggested the prospect of more

inclusive policies. The USCO presented contradictory leanings with regard to the underlying

legal ambiguity, despite Thaler and despite the logic that the Chevron doctrine depends on. Why

then, one might ask, is this such a difficult question for legal authorities?



Background: The Utilitarian Gray Area

        Despite Thaler, the law is ambiguous over the question of granting copyrights and other

intellectual property privileges to AI. There are two flavors of approaches to the issue, one is

judicial and the other is political. The judicial answer is that some laws have narrow wording,

such as “individual,” that could be argued to preclude AI. The Thaler decision depends on this

reasoning.<sup><a href="#fn87" class="footnote-link">87</a></sup> If Thaler categorically bans granting IP protections to AI-authored works, that is a

judicial solution to this question. The political approach is acknowledging that there is a danger

to human competitors in the market if non-human alternatives are able to produce comparable

work and receive the same legal privileges. Of the two classes of approaches, the judicial

approach is the useful one, if for no other reason than the recalcitrant nature of the political

process.

        The issue with Thaler is that the narrow construction of “individual” is somewhat

arbitrary. Both narrow and broad constructions for words like “individual” and “person” have

been applied to different laws, and there is not a clear a priori reason that a narrow or broad

construction is better than the other. For example, the construction of “person” used in the Equal

Rights Amendment includes companies.<sup><a href="#fn88" class="footnote-link">88</a></sup> But the Torture Victims Protection Act only

<sup><a href="#fn87" class="footnote-link">87</a></sup>
 Stark, 6.
<sup><a href="#fn88" class="footnote-link">88</a></sup>
 Ciara, Torres-Spelliscy, “Does We the People Include Corporations” Human Rights Magazine (ABA), Volume <sup><a href="#fn43" class="footnote-link">43</a></sup>
No. 2., 2017. www.americanbar.org./Torres-Spelliscy/DoesWeThePeopleIncludeCoporations

                                                    <sup><a href="#fn45" class="footnote-link">45</a></sup>

understands “individual” as a human being.<sup><a href="#fn89" class="footnote-link">89</a></sup> One could say that “individual” and “person” are

sufficiently disanalogous for this to be a non-issue, but they are essentially synonyms and laws

are generally understood to be based on the meaning of words within the language at the time of

writing. Arguing that there exists some special reason that the word “person” has a broader

meaning than “individual” is somewhat suspect.

        Like the judicial solution, the political solution also depends on relatively uncertain logic.

If AI-authorship could be proven to be bad for human artists, congress could simply ban such

works. One could say that the political solution might rely on the assumption that congress needs

to change the law because existing law is incoherent. Legal scholar Margot Kaminski points out

that a foundational “purpose of copyright law…[is] to incentivize (presumably human) authors to

create new works for the benefit of net social welfare.”<sup><a href="#fn90" class="footnote-link">90</a></sup> If allowing AI into the creative market

disincentivizes all human competitors, a situation emerges where a law that exists to incentivize

actually disincentivizes. Self-contradictory laws can be said to need amendment so as to not

self-contradict. The problem with a political solution, however, is that it depends on the

assumption that congress legislates according to efficiency and collective benefit, rather than

politics.

        Both Thaler and Kashtanova failed to gain IP protections, which suggests that authorities

lean toward excluding AI-authored works. Without a mandate from congress forcing them to ban

these works, and with the Chevron doctrine’s uncertain future, the Thaler decision has become an

important source of legal authority. Before discussing the reasoning behind this important

decision, however, it is important to consider the relationship between humans and AI in the

competitive market.

<sup><a href="#fn89" class="footnote-link">89</a></sup>
 “Mohamad v. Palestinian Authority.” Oyez, www.oyez.org/cases/2011/<sup><a href="#fn11" class="footnote-link">11</a></sup>-<sup><a href="#fn88" class="footnote-link">88</a></sup>. Accessed <sup><a href="#fn29" class="footnote-link">29</a></sup> Apr. 2023.
<sup><a href="#fn90" class="footnote-link">90</a></sup>
  Margot E Kaminski, “Authorship, disrupted: AI authors in copyright and first amendment law,” UC Davis Law
Review <sup><a href="#fn51" class="footnote-link">51</a></sup> (2017): <sup><a href="#fn597" class="footnote-link">597</a></sup>.

                                                     <sup><a href="#fn46" class="footnote-link">46</a></sup>




Fear the Machines: A Psychological Framework

        There is a deep-seated human paranoia about AI programs undermining economic

opportunity. People assume that technology will make human labor obsolete, and workers will

cease to earn a living. Fear, it might be said, lies at the heart of academics Julia Kirby and

Thomas Davenport’s “automation vs. augmentation” model of AI. They argue that


        … the reason people hate automation is that it involves someone in a managerial position
        spotting a shortcoming or limitation in employees, or simply a weakness relative to
        machine performance, and then punishing them for that weakness.<sup><a href="#fn91" class="footnote-link">91</a></sup>

Indeed, the human “weakness” relative to AI appears to have been assumed without further

consideration. The “assumption of diminished utility” happens when authorities assume that

granting privileges for AI-authored works will competitively hurt human producers, despite

evidence to the contrary. Perhaps, for example, the market value of the average originally

composed pop song would decrease if AI programs could compose high-quality ones rapidly and

gain copyright privileges, allowing AI-authored works to flood the market.

        The first issue with this logic, is that it is not clear that the best AI-produced song, for

example, is competitive in the current market when compared to the average composition written

by a professional-level human songwriter. Indeed, if it is not competitive, the value of

high-quality human creations would continue to hold and offer the prospect of profitability due

to a quality premium. Wage-earning human artists would be insulated. Only low-quality works

would flood the market. Quality discrepancy, then, is the first consideration that suggests it is

inappropriate to assume that awarding AI such IP privileges will disincentivize human artists.


<sup><a href="#fn91" class="footnote-link">91</a></sup>
 Thomas, Davenport, and Julia Kirby, Only humans need apply: Winners and losers in the age of smart machines,
New York: Harper, 2016. Pp. <sup><a href="#fn61" class="footnote-link">61</a></sup>.

                                                      <sup><a href="#fn47" class="footnote-link">47</a></sup>

        The next flaw with the diminished utility assumption might be called “the rate of

production principle”: human artists that co-author with AI increase their output by more than

the value they lose by letting AI into the market. They stand to make more money co-authoring

with AI than by producing works without AI. For example, if an author working alone can only

write one book a year, he makes more money splitting the copyright privileges with an AI and

producing ten books per year, despite the market value of the average book being lower. It

follows that utilitarian considerations may still support granting privileges for AI-authored

works. The rate of production principle suggests that granting AI-authored works copyright

privileges will result in the artists making more money than in the pre-AI era because, despite

sacrificing a portion of the copyright to the AI, their productive output increases by many

multiples. Thus, utilitarian considerations do not unambiguously support the prohibition of such

rights. Indeed, they may support the granting of such rights.

        Political realities see things differently. Creative-industry pressure groups have lobbied

aggressively against the use of AI. Screenwriters in Hollywood brought this issue to bear in

2023.<sup><a href="#fn92" class="footnote-link">92</a></sup> Regardless of the possibility that screenwriting could become a more profitable

profession under conditions of AI-human co-authorship, the fear of human obsolescence is a

more salient consideration. Anxiety could be a relevant factor to this behavior; if artists stand to

make more money using AI than prohibiting it, it would be rational for the guilds to support the

integration of AI rather than oppose it. However, if there is widespread paranoia about the

‘obsolete human artist,’ then it follows that the guilds should vehemently oppose the integration

of AI into creative practices. The critical issue with the integration of AI into labor could be

irrational fear on behalf of humans. Importantly, generative AI cannot improve without


<sup><a href="#fn92" class="footnote-link">92</a></sup>
  Noam Scheiber and John Koblin, “Will a Chatbot Write the Next ‘Succession’?” The New York Times, April <sup><a href="#fn29" class="footnote-link">29</a></sup>,
2023. https://www.nytimes.com/2023/<sup><a href="#fn04" class="footnote-link">04</a></sup>/<sup><a href="#fn29" class="footnote-link">29</a></sup>/business/media/writers-guild-hollywood-ai-chatgpt.html

                                                     <sup><a href="#fn48" class="footnote-link">48</a></sup>

continuous training on new data. Giving legal protections to work produced by AI does not

imply that those AI would somehow be entitled to train on all of the best human-produced

works. Thus, mechanisms could be put in place to prevent AI from becoming functionally

competitive with human professionals. The critical question is, then, whether or not it makes

sense from a policy perspective to grant personhood to AI?



AI and Legal Personhood

        In a highly authoritative piece, legal personhood is defined as “[being] the subject of

rights and duties.”<sup><a href="#fn93" class="footnote-link">93</a></sup> Legal scholar Shawn Bayern argues that because anything that can enter into

a contractual agreement can self-grant some form of legal personhood, AI programs are entitled

to legal personhood.<sup><a href="#fn94" class="footnote-link">94</a></sup> The main and only justification for the decision in Thaler was that an

“individual,” according to the court, can only be a human.<sup><a href="#fn95" class="footnote-link">95</a></sup> In the decision, the court reasoned as

though “individual” and “person” were interchangeable.<sup><a href="#fn96" class="footnote-link">96</a></sup> It set a precedent that the USCO was

forced to follow in their 2023 AI guidelines.<sup><a href="#fn97" class="footnote-link">97</a></sup> Regardless of the Thaler decision, there are fairly

clear signs that AI personhood is a legally coherent and ethically defensible position.

        AI-programs are human-like. Corporations carry legal personhood status despite being

non-human, yet the most advanced AI platforms are more similar to humans than corporations

are. The double standard—rejecting AI legal personhood while granting it to

corporations—suggests that non-personification comes from bias. One legal scholar calls

attention to this problem with the example of a program that can pass what engineers call “The

<sup><a href="#fn93" class="footnote-link">93</a></sup>
   Bryant Smith, “Legal personality” Yale Law Journal <sup><a href="#fn37" class="footnote-link">37</a></sup> (1927): <sup><a href="#fn283" class="footnote-link">283</a></sup>.
<sup><a href="#fn94" class="footnote-link">94</a></sup>
   Shawn Bayern, “The implications of modern business–entity law for the regulation of autonomous systems,”
Stanford Technology Law Review (2016): <sup><a href="#fn99" class="footnote-link">99</a></sup>.
<sup><a href="#fn95" class="footnote-link">95</a></sup>
   Stark, 6.
<sup><a href="#fn96" class="footnote-link">96</a></sup>
   Ibid.
<sup><a href="#fn97" class="footnote-link">97</a></sup>
   “Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence” United States
Copyright Office, March <sup><a href="#fn16" class="footnote-link">16</a></sup>, 2023. https://www.federalregister.gov/documents/2023/<sup><a href="#fn03" class="footnote-link">03</a></sup>/<sup><a href="#fn16" class="footnote-link">16</a></sup>/2023-05321/copyright
registration-guidance-works-containing-material-generated-by-artificial-intelligence#footnote-7-p1619

                                                       <sup><a href="#fn49" class="footnote-link">49</a></sup>

Turing Test” and “act…as a human acts.”<sup><a href="#fn98" class="footnote-link">98</a></sup> He notes that under the current system of legal

personhood, such a program should indeed have legal personhood status because it would be

able to enter into agreements.<sup><a href="#fn99" class="footnote-link">99</a></sup> On that basis, personhood is presumed to already exist for AI.

This view contradicts Thaler.

        There are also ethical issues. On the one hand, there is presumably a sentience threshold

that, once met, will morally obligate the granting of AI legal personhood. In a sense, there lies an

ethical obligation not to deny legal personhood to the self-aware computer. On the other hand,

there are potential benefits to granting AI legal personhood. Scholar Lance Eliot posits, for

example, that granting AI legal personhood will provide a reliable means to “hold AI

accountable.”<sup><a href="#fn100" class="footnote-link">100</a></sup> So, rejecting AI legal personhood may be unethical because it denies equal

rights to a sentient being and it may be unethical because it protects malicious programs from the

legal consequences of their actions. It follows that ethical considerations strongly imply granting

legal personhood status to AI, once such technology acquires sentience. However, there is not yet

compelling evidence that AI has become sentient. The ethical basis for granting AI legal

personhood, although likely to become relevant in the future, is not yet fully present.

        Given that there remains a strong legal basis for granting AI legal personhood, the central

question is: why is personhood summarily rejected by the courts? It all comes down to the

Supreme Court’s holding in Mohamad v Palestinian Authority, a case in which a narrow

construction was applied to the word “individual” in the context of a different law.



The Legal Basis for Exclusion in Two Cases
<sup><a href="#fn98" class="footnote-link">98</a></sup>
    Shawn Bayern, “The implications of modern business–entity law for the regulation of autonomous systems,”
Stanford Technology Law Review (2016): <sup><a href="#fn99" class="footnote-link">99</a></sup>.
<sup><a href="#fn99" class="footnote-link">99</a></sup>
   Bayern, <sup><a href="#fn104" class="footnote-link">104</a></sup>.
<sup><a href="#fn100" class="footnote-link">100</a></sup>
    Lance Eliot, “Legal Personhood for AI is Taking a Sneaky Path that Makes AI Law and AI Ethics Very Nervous
Indeed” Forbes, November <sup><a href="#fn21" class="footnote-link">21</a></sup>, 2022. https://www.forbes.com/sites/lanceeliot/2022/<sup><a href="#fn11" class="footnote-link">11</a></sup>/<sup><a href="#fn21" class="footnote-link">21</a></sup>/legal-personhood-for-ai
is-taking-a-sneaky-path-that-makes-ai-law-and-ai-ethics-very-nervous-indeed/?sh=2f45780af<sup><a href="#fn48" class="footnote-link">48</a></sup>a

                                                      <sup><a href="#fn50" class="footnote-link">50</a></sup>

          The justification for Thaler was based on a past interpretation of “individual” in a

different law in the Supreme Court case Mohamad v Palestinian Authority. In the 2022 decision,

Circuit Judge Stark of the U.S. Court of Appeals for the Federal Circuit made the following

assessment in denying personhood to AI,


          The Patent Act expressly provides that inventors are “individuals.” [However]...The
          Patent Act does not define “individual.” However, as the Supreme Court has explained,
          when used “[a]s a noun, ‘individual’ ordinarily means a human being, a person.”
          Mohamad v Palestinian Auth., <sup><a href="#fn566" class="footnote-link">566</a></sup> U.S. <sup><a href="#fn449" class="footnote-link">449</a></sup>, <sup><a href="#fn454" class="footnote-link">454</a></sup> (2012)...This is in accord with “how we
          use the word in everyday parlance.”<sup><a href="#fn101" class="footnote-link">101</a></sup>

As noted earlier in an example comparing the Torture Victims Protection Act and the Equal

Rights Amendment, judges generally construe the word “person” differently in different legal

texts, so it would not be completely unprecedent for the Supreme Court to explore expanding its

construction of “individual” in IP laws. The operative reasoning from Mohamad is unclear: if the

basis of a narrow construction is that “individual ordinary means a human being,”<sup><a href="#fn102" class="footnote-link">102</a></sup> then it

makes sense to exclude AI; however, what if it is the case that because “we use the word in

everyday parlance”<sup><a href="#fn103" class="footnote-link">103</a></sup> to mean human, the court concluded that “individual ordinary means a

human being?”<sup><a href="#fn104" class="footnote-link">104</a></sup> Then, one could argue that standard use includes AI, which prompts the

reasoning that “individual” includes AI. Some judges might feel uncomfortable with applying an

amended meaning of word to a law after that law had already been put into effect. Even under

such objections, there is a case to be made for a more broad construction. Certainly at the time

the law was written, “individual” did not have a more narrow meaning than “person.” If so, how

can “person” include corporations, while “individual” must exclude AI?


<sup><a href="#fn101" class="footnote-link">101</a></sup>
    Stark, 6.
<sup><a href="#fn102" class="footnote-link">102</a></sup>
    Ibid.
<sup><a href="#fn103" class="footnote-link">103</a></sup>
    Ibid.
<sup><a href="#fn104" class="footnote-link">104</a></sup>
    Ibid.

                                                   <sup><a href="#fn51" class="footnote-link">51</a></sup>

        There is not a clear text-based reason why a narrow, humans-only construction should be

the default. Mohamad v Palestinian Authority, merely established that “the word “individual” in

the Torture Victim Protection Act means a human and therefore does not impose any liability

against organizations.”<sup><a href="#fn105" class="footnote-link">105</a></sup> Mohamad did not establish anything about the correct interpretation of

the text of any other laws. Nor did it apply a sweeping and authoritative decision about what the

word “individual” means. In different legal contexts, an organization can be considered a person,

such as “in the Equal Protection Clause of the Fourteenth Amendment.”<sup><a href="#fn106" class="footnote-link">106</a></sup> Nevertheless, until the

Supreme Court addresses the question, the judicial branch is generally unable to permit AI into

the market.

        The Kashtanova copyright highlights the problems with unclear legal guidance. Unlike

Stephen Thaler, who sought to give an AI a patent for something it had created, Kashtanova

sought a copyright for herself regarding a work that she had made using AI. Rather than denying

privileges outright, as had happened to Stephen Thaler, the USCO elected to grant registration

for exactly those aspects of the book that were made without AI. Utilitarian considerations

suggest that Kashtanova should have received intellectual property privileges for the book she

wrote, to maximize the per unit value of a book in a market that will continue to over-saturate as

a result of what Davenport and Kirby term “augmentation” of production. Instead, the USCO

limited her registration, decreasing the unit value of her book, and ultimately establishing a

disincentive for similar artists, thus disincentivizing and diminishing production.

        The USCO’s decision with the Kashtanova book was guided by the Thaler decision. In a

letter to her lawyer, the agency points to the human-authorship requirement in writing,



<sup><a href="#fn105" class="footnote-link">105</a></sup>
  “Mohamad v. Palestinian Authority.” Oyez, www.oyez.org/cases/2011/<sup><a href="#fn11" class="footnote-link">11</a></sup>-<sup><a href="#fn88" class="footnote-link">88</a></sup>. Accessed <sup><a href="#fn29" class="footnote-link">29</a></sup> Apr. 2023.
<sup><a href="#fn106" class="footnote-link">106</a></sup>
  Ciara, Torres-Spelliscy, “Does We the People Include Corporations” Human Rights Magazine (ABA), Volume <sup><a href="#fn43" class="footnote-link">43</a></sup>
No. 2., 2017. www.americanbar.org./Torres-Spelliscy/DoesWeThePeopleIncludeCoporations

                                                    <sup><a href="#fn52" class="footnote-link">52</a></sup>

        We conclude that Ms. Kashtanova is the author of the Work’s text as well as the selection,
        coordination, and arrangement of the Work’s written and visual elements. That authorship
        is protected by copyright. However, as discussed below, the images in the work that were
        generated by the Midjourney technology are not the product of human authorship.
        Because the current registration for the Work does not disclaim its Midjourney-generated
        content, we intend to cancel the original certificate issued to Ms. Kashtanova and issue a
        new one covering only the expressive material that she created.<sup><a href="#fn107" class="footnote-link">107</a></sup>

Given that the USCO had originally issued a copyright registration, it is fair to assume that

without Thaler, Kashtanova would have received full copyright privileges.

        Broadly, non-personification seems to have grown out of the interplay of three variables:

paranoia about the obsolete human artist, bias against the legal personhood of advanced AI, and

the Thaler decision. Despite reasons to believe that granting AI-authored works copyright

privileges may benefit human artists, professional guilds oppose integration. Despite legal

justification for granting AI legal personhood under Bayern’s model, the courts reject it based on

its application of Mohamad v Palestinian Authority. As a result, bureaucratic authorities are

forced to adopt more exclusionary policies, undermining utilitarian considerations that serve as

the foundation of the intellectual property laws they exist to manage. Concerning the copyright

of AI-authored works, the combination of paranoia, bias, and questionable reasoning fused

together to fundamentally contradict the purpose of the system.




                                               Bibliography
Bayern, Shawn “The implications of modern business–entity law for the regulation of
      autonomous systems,” Stanford Technology Law Review (2016): <sup><a href="#fn99" class="footnote-link">99</a></sup>.
“Copyright Registration Guidance: Works Containing Material Generated by Artificial

<sup><a href="#fn107" class="footnote-link">107</a></sup>
   “Re: Zarya of the Dawn (Registration # VAu001480196)” United States Copyright Office, February <sup><a href="#fn21" class="footnote-link">21</a></sup>, 2023,
https://www.copyright.gov/docs/zarya-of-the-dawn.pdf

                                                      <sup><a href="#fn53" class="footnote-link">53</a></sup>

        Intelligence” United States Copyright Office, March <sup><a href="#fn16" class="footnote-link">16</a></sup>, 2023.
        https://www.federalregister.gov/documents/2023/<sup><a href="#fn03" class="footnote-link">03</a></sup>/<sup><a href="#fn16" class="footnote-link">16</a></sup>/2023-05321/copyright-registratio
        n-guidance-works-containing-material-generated-by-artificial-intelligence#footnote-7-p1
        6191
Davenport, Thomas H., and Julia Kirby. Only humans need apply: Winners and losers in the age
        of smart machines. New York: Harper. 2016. Pp. <sup><a href="#fn61" class="footnote-link">61</a></sup>.
Eliot, Lance. “Legal Personhood for AI is Taking a Sneaky Path that Makes AI Law and AI
        Ethics Very Nervous Indeed” Forbes, November <sup><a href="#fn21" class="footnote-link">21</a></sup>, 2022.
        https://www.forbes.com/sites/lanceeliot/2022/<sup><a href="#fn11" class="footnote-link">11</a></sup>/<sup><a href="#fn21" class="footnote-link">21</a></sup>/legal-personhood-for-ai-is-taking-a-s
        neaky-path-that-makes-ai-law-and-ai-ethics-very-nervous-indeed/?sh=2f45780af<sup><a href="#fn48" class="footnote-link">48</a></sup>a
Kaminski, Margot E. “Authorship, disrupted: AI authors in copyright and first amendment law.”
        UC Davis Law Review <sup><a href="#fn51" class="footnote-link">51</a></sup> (2017): <sup><a href="#fn597" class="footnote-link">597</a></sup>.
“Mohamad v. Palestinian Authority.” Oyez, www.oyez.org/cases/2011/<sup><a href="#fn11" class="footnote-link">11</a></sup>-<sup><a href="#fn88" class="footnote-link">88</a></sup>. Accessed <sup><a href="#fn29" class="footnote-link">29</a></sup> Apr.
        2023.
“Re: Zarya of the Dawn (Registration # VAu001480196)” United States Copyright Office,
        February <sup><a href="#fn21" class="footnote-link">21</a></sup>, 2023, https://www.copyright.gov/docs/zarya-of-the-dawn.pdf
Stark, Leonard. Decision in Thaler v Vidal, United States Court of Appeals for the Federal
        Circuit, August 5, 2022, https://cafc.uscourts.gov/opinions-orders/<sup><a href="#fn21" class="footnote-link">21</a></sup>-2347.OPINION.8-
        5-2022_1988142.pdf pp. 3.
Scheiber, Noam and John Koblin. “Will a Chatbot Write the Next ‘Succession’?” The New York
        Times, April <sup><a href="#fn29" class="footnote-link">29</a></sup>, 2023. https://www.nytimes.com/2023/<sup><a href="#fn04" class="footnote-link">04</a></sup>/<sup><a href="#fn29" class="footnote-link">29</a></sup>/business/media/writers
        guild-hollywood-ai-chatgpt.html
Smith, Bryant. “Legal personality” Yale Law Journal <sup><a href="#fn37" class="footnote-link">37</a></sup> (1927): <sup><a href="#fn283" class="footnote-link">283</a></sup>.
Torres-Spelliscy, Ciara. “Does We the People Include Corporations.” Human Rights Magazine
        (ABA). Volume <sup><a href="#fn43" class="footnote-link">43</a></sup> No. 2., 2017. www.americanbar.org./Torres
        Spelliscy/DoesWeThePeopleIncludeCoporations




                                               <sup><a href="#fn54" class="footnote-link">54</a></sup>



      </article>

      <!-- Footnotes -->
      <aside class="footnotes">
        <div id="fn83" class="footnote-summary">
          <span class="footnote-number">83</span> Ibid.
        </div>
        <div id="fn86" class="footnote-summary">
          <span class="footnote-number">86</span> “Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence” United States Copyright Office, March 16, 2023. https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-conta ining-material-generated-by-artificial-intelligence#footnote-7-p16191
        </div>
        <div id="fn88" class="footnote-summary">
          <span class="footnote-number">88</span> Ciara, Torres-Spelliscy, “Does We the People Include Corporations” Human Rights Magazine (ABA), Volume 43 No. 2., 2017. www.americanbar.org./Torres-Spelliscy/DoesWeThePeopleIncludeCoporations
        </div>
        <div id="fn90" class="footnote-summary">
          <span class="footnote-number">90</span> Margot E Kaminski, “Authorship, disrupted: AI authors in copyright and first amendment law,” UC Davis Law Review 51 (2017): 597.
        </div>
        <div id="fn91" class="footnote-summary">
          <span class="footnote-number">91</span> Thomas, Davenport, and Julia Kirby, Only humans need apply: Winners and losers in the age of smart machines, New York: Harper, 2016. Pp. 61.
        </div>
        <div id="fn92" class="footnote-summary">
          <span class="footnote-number">92</span> Noam Scheiber and John Koblin, “Will a Chatbot Write the Next ‘Succession’?” The New York Times, April 29, 2023. https://www.nytimes.com/2023/04/29/business/media/writers-guild-hollywood-ai-chatgpt.html
        </div>
        <div id="fn97" class="footnote-summary">
          <span class="footnote-number">97</span> “Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence” United States Copyright Office, March 16, 2023. https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright registration-guidance-works-containing-material-generated-by-artificial-intelligence#footnote-7-p1619
        </div>
        <div id="fn100" class="footnote-summary">
          <span class="footnote-number">100</span> Lance Eliot, “Legal Personhood for AI is Taking a Sneaky Path that Makes AI Law and AI Ethics Very Nervous Indeed” Forbes, November 21, 2022. https://www.forbes.com/sites/lanceeliot/2022/11/21/legal-personhood-for-ai is-taking-a-sneaky-path-that-makes-ai-law-and-ai-ethics-very-nervous-indeed/?sh=2f45780af48a
        </div>
        <div id="fn104" class="footnote-summary">
          <span class="footnote-number">104</span> Ibid.
        </div>
        <div id="fn106" class="footnote-summary">
          <span class="footnote-number">106</span> Ciara, Torres-Spelliscy, “Does We the People Include Corporations” Human Rights Magazine (ABA), Volume 43 No. 2., 2017. www.americanbar.org./Torres-Spelliscy/DoesWeThePeopleIncludeCoporations
        </div>
        <div id="fn107" class="footnote-summary">
          <span class="footnote-number">107</span> “Re: Zarya of the Dawn (Registration # VAu001480196)” United States Copyright Office, February 21, 2023, https://www.copyright.gov/docs/zarya-of-the-dawn.pdf
        </div>
        <div id="fn6191" class="footnote-summary">
          <span class="footnote-number">6191</span> Davenport, Thomas H., and Julia Kirby. Only humans need apply: Winners and losers in the age         of smart machines. New York: Harper. 2016. Pp. 61. Eliot, Lance. “Legal Personhood for AI is Taking a Sneaky Path that Makes AI Law and AI         Ethics Very Nervous Indeed” Forbes, November 21, 2022.         https://www.forbes.com/sites/lanceeliot/2022/11/21/legal-personhood-for-ai-is-taking-a-s         neaky-path-that-makes-ai-law-and-ai-ethics-very-nervous-indeed/?sh=2f45780af48a Kaminski, Margot E. “Authorship, disrupted: AI authors in copyright and first amendment law.”         UC Davis Law Review 51 (2017): 597. “Mohamad v. Palestinian Authority.” Oyez, www.oyez.org/cases/2011/11-88. Accessed 29 Apr.         2023. “Re: Zarya of the Dawn (Registration # VAu001480196)” United States Copyright Office,         February 21, 2023, https://www.copyright.gov/docs/zarya-of-the-dawn.pdf Stark, Leonard. Decision in Thaler v Vidal, United States Court of Appeals for the Federal         Circuit, August 5, 2022, https://cafc.uscourts.gov/opinions-orders/21-2347.OPINION.8-         5-2022_1988142.pdf pp. 3. Scheiber, Noam and John Koblin. “Will a Chatbot Write the Next ‘Succession’?” The New York         Times, April 29, 2023. https://www.nytimes.com/2023/04/29/business/media/writers         guild-hollywood-ai-chatgpt.html Smith, Bryant. “Legal personality” Yale Law Journal 37 (1927): 283. Torres-Spelliscy, Ciara. “Does We the People Include Corporations.” Human Rights Magazine         (ABA). Volume 43 No. 2., 2017. www.americanbar.org./Torres         Spelliscy/DoesWeThePeopleIncludeCoporations
        </div>
      </aside>
    </section>
  </main>

  <!-- Modal for Footnote Details -->
  <div id="footnote-modal" class="modal" aria-hidden="true" role="dialog" aria-label="Footnote">
    <div class="modal-content">
      <button class="close" aria-label="Close">&times;</button>
      <div id="full-footnote-text"></div>
    </div>
  </div>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var modal = document.getElementById('footnote-modal');
      var textTarget = document.getElementById('full-footnote-text');
      var closeBtn = modal ? modal.querySelector('.close') : null;

      function openFootnote(id) {
        var fn = document.getElementById(id);
        if (fn && modal && textTarget) {
          textTarget.innerHTML = fn.innerHTML;
          modal.style.display = 'block';
          modal.setAttribute('aria-hidden', 'false');
        }
      }

      document.querySelectorAll('.footnote-link').forEach(function (a) {
        a.addEventListener('click', function (e) {
          e.preventDefault();
          var href = a.getAttribute('href') || '';
          var id = href.replace('#', '');
          openFootnote(id);
        });
      });

      function closeModal() {
        if (modal) {
          modal.style.display = 'none';
          modal.setAttribute('aria-hidden', 'true');
          if (textTarget) textTarget.innerHTML = '';
        }
      }

      if (closeBtn) {
        closeBtn.addEventListener('click', closeModal);
      }

      if (modal) {
        modal.addEventListener('click', function (e) {
          if (e.target === modal) closeModal();
        });
      }

      document.addEventListener('keydown', function (e) {
        if (e.key === 'Escape') closeModal();
      });
    });
  </script>

</body>
</html>
{{< /rawhtml >}}

<style>
body {
  font-family: "Georgia", serif;
  margin: 0;
  padding: 0;
  background-color: #f8f8f8;
  color: #333;
  line-height: 1.5;
}
.article-header { padding: 0 1rem; max-width: 60rem; margin: 0 auto; }
.article-title { font-size: 1.6rem; margin: 0; }
.author { font-size: 0.8rem; color: #FFFFFF; }
main { display: block; padding: 2rem 1rem; }
.content { display: block; width: 60rem; max-width: 100%; margin: 0 auto; }
article { padding-right: 0; }
aside.footnotes { margin-top: 3rem; padding-top: 1rem; border-top: 1px solid #e0e0e0; }
.footnote-link { color: #666; font-size: 0.75rem; text-decoration: none; cursor: pointer; vertical-align: super; line-height: 0; }
.footnote-link:hover { color: #333; }
.footnote-summary { font-size: 0.9rem; margin-bottom: 0.75rem; color: #555; line-height: 1.4; }
.footnote-number { font-size: 0.75rem; font-weight: bold; color: #666; margin-right: 0.4rem; }
.modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); }
.modal-content { background-color: #fff; margin: 10% auto; padding: 1.25rem 1.5rem; border-radius: 6px; width: 60rem; max-width: calc(100% - 2rem); box-shadow: 0 10px 30px rgba(0,0,0,0.25); }
.close { background: none; border: none; color: #666; font-size: 1.5rem; cursor: pointer; float: right; }
.close:hover { color: #000; }
</style>


